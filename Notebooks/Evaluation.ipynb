{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23abc72-043d-4f69-8789-294bba1e3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800cba7f-f5cf-4bf0-8bc7-4926d6606b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4bf351-b7cb-457a-9622-dd765e44ee21",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/home/hv2237/bart_rl/step_1500 does not appear to have a file named config.json. Checkout 'https://huggingface.co//home/hv2237/bart_rl/step_1500/None' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5754/2473771416.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/hv2237/bart_rl/step_1500'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/transformers/src/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             )\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0moriginal_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                     \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0msubfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m                     \u001b[0m_commit_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m                 )\n\u001b[1;32m    628\u001b[0m                 \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_commit_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommit_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_raise_exceptions_for_missing_entries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 raise EnvironmentError(\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0;34mf\"{path_or_repo_id} does not appear to have a file named {full_filename}. Checkout \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                     \u001b[0;34mf\"'https://huggingface.co/{path_or_repo_id}/{revision}' for available files.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 )\n",
      "\u001b[0;31mOSError\u001b[0m: /home/hv2237/bart_rl/step_1500 does not appear to have a file named config.json. Checkout 'https://huggingface.co//home/hv2237/bart_rl/step_1500/None' for available files."
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained('/home/hv2237/bart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0df1b1-3b0f-4a62-b102-a9269e2976f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/hv2237/GYAFC_Corpus/Entertainment_Music'\n",
    "data = {}\n",
    "        \n",
    "for split in ['tune', 'test']:\n",
    "    data[split] = []\n",
    "    refs = [open(f'{path}/{split}/formal.ref{i}').readlines() for i in range(4)]\n",
    "    inp = open(f'{path}/{split}/informal').readlines()\n",
    "    for f in range(len(inp)):\n",
    "        temp = {}\n",
    "        temp['informal'] = inp[f][:-1]\n",
    "        for i in range(4):\n",
    "            temp[f'formal.ref{i}'] = refs[i][f][:-1]\n",
    "        data[split].append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6da9443-4b48-4a92-9e08-9033f1e1c2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'informal': 'Any movie that has vampires I like!',\n",
       " 'formal.ref0': 'I like any movie that has vampires in it.',\n",
       " 'formal.ref1': 'I enjoy any film that has vampires in it!',\n",
       " 'formal.ref2': 'I enjoy any film that has vampires.',\n",
       " 'formal.ref3': 'I like any movie with vampires!'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tune'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31e40aa3-df2a-481b-9ec1-30a69a7c269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "for split in ['tune', 'test']:\n",
    "    json.dump(data[split], open(f'eval_{split}.json','w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13c46c28-fe02-4c50-a804-0e8a7c53def9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-af09d24aeef2f376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/hv2237/.cache/huggingface/datasets/json/default-af09d24aeef2f376/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240eed8408924c25b0a68438346264d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20f7937377947a4b644a2044e2ee0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/hv2237/.cache/huggingface/datasets/json/default-af09d24aeef2f376/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2eafe862e41444094f216d0380d5be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "eval_dataset = load_dataset('json',data_files={\n",
    "    'valid':'eval_tune.json',\n",
    "    'test':'eval_test.json'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60a4859c-0d74-4457-aa48-ca9285a7a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function_eval(examples):\n",
    "    # print(examples)\n",
    "    inputs = [ex for ex in examples[\"informal\"]]\n",
    "    targets = [ex for ex in examples[\"formal.ref0\"]]\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, text_target=targets, max_length=max_length, truncation=True\n",
    "    )\n",
    "    for i in range(4):\n",
    "        model_inputs[f'formal{i}'] = examples[f'formal.ref{i}']\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f01ef802-a9b7-4c77-bac0-770638456c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591a952f23fc43adbd3a130c2ec1e78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9d1ae899684b5fa5c0d56ff0508435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 30\n",
    "tokenized_datasets_eval = eval_dataset.map(\n",
    "    preprocess_function_eval,\n",
    "    batched=True,\n",
    "    remove_columns=eval_dataset[\"valid\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38618641-dc53-4b1b-aa11-3f696ff5c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    keys = list(batch[0].keys())\n",
    "    cols = {key:[] for key in keys}\n",
    "    temp = list(map(lambda x: {'input_ids':x['input_ids'], 'labels':x['labels'], 'attention_mask':x['attention_mask']}, batch))\n",
    "    for i in batch:\n",
    "        for key in i:\n",
    "            cols[key].append(i[key])\n",
    "    out = data_collator(temp)\n",
    "    for i in range(4):\n",
    "        out[f'formal{i}'] = cols[f'formal{i}']\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fa3b9fd-de3b-4418-8d69-33227ebe4a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "628abd6f-3b99-4c37-acf3-79aee63e6a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenized_datasets_eval.set_format(\"torch\")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets_eval[\"valid\"],collate_fn=lambda x: collate(x) ,  batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a11b1fc0-4428-4d0b-80bb-a7f5f246b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets_eval[\"test\"],collate_fn=lambda x: collate(x) ,  batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0478c2b-b572-47a3-ba95-a2b8f225015d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13d723c5-a368-4f8a-a6d0-240a33ba2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, eval_dataloader, test_dataloader = accelerator.prepare(\n",
    "    model, eval_dataloader, test_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d50cd90-2e5a-406c-8932-df7eab267d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "    return decoded_preds, decoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c62a55-6b6f-496a-8614-1e6d03f92313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "49fcbd62-342b-4215-93c2-10a9890e8c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d2cc4138fa42488ee7e244e1eed84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e9f1251573408fb7bec458322e17c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.75\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "metric_bleu = evaluate.load('bleu')\n",
    "predictions, references = [], []\n",
    "model.eval()\n",
    "for batch in tqdm(eval_dataloader):\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "            batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            max_length=30,\n",
    "            num_beams=10\n",
    "        )\n",
    "    labels = batch[\"labels\"]\n",
    "    \n",
    "    # Necessary to pad predictions and labels for being gathered\n",
    "    generated_tokens = accelerator.pad_across_processes(\n",
    "        generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "    )\n",
    "    labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "    predictions_gathered = accelerator.gather(generated_tokens)\n",
    "    labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "    predictions += [i for i in decoded_preds]\n",
    "    # for ref in batch\n",
    "    # for i in range(1,4):\n",
    "    transfrom = lambda x: [i for i in x]\n",
    "    references += list(map(list, zip(*map(transform, [batch[f'formal{i}'] for i in range(4)]))))\n",
    "    # metric_bleu.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "    # metric_bleurt.add_batch(predictions=decoded_preds, references=list(map(lambda x: x[0],decoded_labels)))\n",
    "    # for i in range(1,4):\n",
    "    #     metric_bleu.add_batch(predictions=decoded_preds, references=[[i] for i in batch[f'formal{i}']])\n",
    "        # metric_bleurt.add_batch(predictions=decoded_preds, references=[i for i in batch[f'formal{i}']])\n",
    "    \n",
    "results_bleu = metric_bleu.compute(predictions=predictions, references=references, tokenizer=word_tokenize)\n",
    "# results_bleurt = metric_bleurt.compute()\n",
    "# bleurt = np.mean(results_bleurt['scores'])\n",
    "print(f\"BLEU score: {results_bleu['bleu']:.2f}\")\n",
    "\n",
    "metric_bleu = evaluate.load('bleu')\n",
    "predictions, references = [], []\n",
    "\n",
    "for batch in tqdm(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "            batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            max_length=30,\n",
    "        )\n",
    "    labels = batch[\"labels\"]\n",
    "\n",
    "    # Necessary to pad predictions and labels for being gathered\n",
    "    generated_tokens = accelerator.pad_across_processes(\n",
    "        generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "    )\n",
    "    labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "    predictions_gathered = accelerator.gather(generated_tokens)\n",
    "    labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "    predictions += [i for i in decoded_preds]\n",
    "    # for ref in batch\n",
    "    # for i in range(1,4):\n",
    "    transfrom = lambda x: [i for i in x]\n",
    "    references += list(map(list, zip(*map(transform, [batch[f'formal{i}'] for i in range(4)]))))\n",
    "\n",
    "    # metric_bleu.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "    # metric_bleurt.add_batch(predictions=decoded_preds, references=list(map(lambda x: x[0],decoded_labels)))\n",
    "    # for i in range(1,4):\n",
    "        # metric_bleu.add_batch(predictions=decoded_preds, references=[[i] for i in batch[f'formal{i}']])\n",
    "        # metric_bleurt.add_batch(predictions=decoded_preds, references=[i for i in batch[f'formal{i}']])\n",
    "\n",
    "# results_bleu = metric_bleu.compute()\n",
    "results_bleu = metric_bleu.compute(predictions=predictions, references=references, tokenizer=word_tokenize)\n",
    "\n",
    "# results_bleurt = metric_bleurt.compute()\n",
    "# bleurt = np.mean(results_bleurt['scores'])\n",
    "print(f\"BLEU score: {results_bleu['bleu']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d4528935-ab56-41f0-a344-ee428540739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hv2237/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8487103e-1407-4b55-9513-bb57a6558521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['It is a great magazine that has good information without having inappropriate things.',\n",
       "  \"It's a great magazine. It has great information, without anything inappropriate.\",\n",
       "  'It is a great magazine with good information and no inappropriate material.',\n",
       "  'It is a good magazine. It has good information about inappropriate topics.'],\n",
       " ['I do not dislike anyone and neither should you.',\n",
       "  \"I don't hate anybody, neither should you.\",\n",
       "  'I do not hate anyone, and neither should you.',\n",
       "  'I do not hate anyone and neither should you.'],\n",
       " ['\"The Real World\", \"The Newlyweds\" and \"Laguna Beach\".',\n",
       "  'I enjoy Laguna Beach, Newlyweds and The Real World programs.',\n",
       "  '\"The Real World,\" \"The Newlyweds,\" and \"Laguna Beach.\"',\n",
       "  '\"The Real World,\" \"Newlyweds,\" and \"Laguna Beach.\"'],\n",
       " ['I think he is too cocky, which annoys me.',\n",
       "  'He is a very cocky person.',\n",
       "  'I think that he is too sure of himself and that agitates me.',\n",
       "  'He is too cocky and that annoys me.'],\n",
       " ['The woman looks up and calls the person a fool.',\n",
       "  'She called him a fool.',\n",
       "  'The woman looks up and says, \"You aged silly man.\"',\n",
       "  'The woman looks up and says, \"You old fool!\"'],\n",
       " ['Susan from Desperate Housewives is a cool mom.',\n",
       "  'I liked the character Susan from the television show Desperate Housewifes.',\n",
       "  'Susan, from, \"Desperate Housewives,\" is a modern mother.',\n",
       "  'Susan from Desperate Housewives because she is a cool mom.'],\n",
       " ['To quote Toy Story, \"To Infinity and Beyond!\"',\n",
       "  \"The quote from Toy Story was 'To infinity, and beyond!'\",\n",
       "  'The catch-phrase that came from, \"Toy Story,\" was, \"To Infinity and Beyond.\"',\n",
       "  'Toy Story says \"To infinity and beyond!\"'],\n",
       " ['She owns it, along with Bill Gates; it is a wide-reaching conspiracy.',\n",
       "  'She and Bill Gates own it. It is also a massive conspiricy.',\n",
       "  'She owns it with Bill Gates because it is a massive conspiracy.',\n",
       "  'She and Bill Gates own it together, it is a massive conspiracy.'],\n",
       " ['In actuality, I can; it is one of my diversions when I socialize.',\n",
       "  'I can, it is one of my party tricks.',\n",
       "  'Yes, I can because it is one of my party tricks.',\n",
       "  'Actually I can, it is a conversation starter at social gatherings.'],\n",
       " ['I truly enjoyed it, it made me cry.',\n",
       "  'I really enjoyed it. It made me cry.',\n",
       "  'I loved it and it made me cry.',\n",
       "  'I loved it, it made me emotional.'],\n",
       " ['My question is: Why does Noddy wear a hat?',\n",
       "  \"Why doesn't anyone wear a hat?\",\n",
       "  'Why does Noddy wear a hat?',\n",
       "  \"Why doesn't anyone wear a hat?\"],\n",
       " ['Only good songs are Country songs.',\n",
       "  'Country songs are the only good songs.',\n",
       "  'The only good songs, are country songs.',\n",
       "  'The only good songs are Country songs.'],\n",
       " ['This is similar to building your own website.',\n",
       "  'This is like building your own website.',\n",
       "  'It is like building your own website.',\n",
       "  'This is like building your own website.'],\n",
       " ['I think it is a great show.',\n",
       "  'It is a good show.',\n",
       "  'I believe it is a great show.',\n",
       "  'I think it is a great show.'],\n",
       " ['With a great deal of therapy, he may walk again.  The man is driving down the road.',\n",
       "  'And with a great deal of therapy, he may even walk again. Man driving down the road.',\n",
       "  'With a great deal of therapy, may even be able to walk once again. A man, driving down the road.',\n",
       "  'With alot of therapy, he may walk again.'],\n",
       " ['Steve Harris from Iron Maiden is the best bass player ever.',\n",
       "  'It is Steve Harris from Iron Maiden. He is the best bass player I have ever heard.',\n",
       "  'Come on, it is Steve Harris, of Iron Maiden, the best bass player that has ever been.',\n",
       "  'Steve Harris from Iron Maiden is a great bass player.'],\n",
       " ['Why does an unintelligent cat fall when it is walking?',\n",
       "  'Why does an unintelligent cat fall when walking?',\n",
       "  'Why does an unintelligent feline fall when walking?',\n",
       "  'Why does the cat fall when walking?'],\n",
       " ['I hope it is the 17 year old girl.',\n",
       "  'I hope that it is the seventeen year old female.',\n",
       "  'Hopefully it is the 17 year old girl.',\n",
       "  'Hopefully it will be the 17 year old.'],\n",
       " ['I like his chin.',\n",
       "  'I am highly attracted to his chin.',\n",
       "  'I find his chin rather attractive.',\n",
       "  'I think his chin is very provocative.'],\n",
       " ['You need to clean it with a soft cloth or tissue with some rubbing alcohol.',\n",
       "  'You should clean it with a soft cloth or tissue soaked in rubbing alcohol.',\n",
       "  'Clean it with a soft cloth or a tissue and rubbing alcohol.',\n",
       "  'Clean it with rubbing alcohol, using a soft cloth or tissue.'],\n",
       " ['She takes a lot of pills.',\n",
       "  'She ingests a lot of pills such as Xanax.',\n",
       "  'She consumes many pills, such as xanex.',\n",
       "  'She takes a lot of medicine, like xanex.'],\n",
       " [\"Because he's a terrible person.\",\n",
       "  'First, because he is a terrible person.',\n",
       "  'He is a real bad guy.',\n",
       "  'He is not a good person.'],\n",
       " [\"If you're willing to take the chance.\",\n",
       "  'You have to be willing to take that chance.',\n",
       "  'If you are willing to take that chance.',\n",
       "  'Are you willing to take that chance?'],\n",
       " ['Who am I? What is my given name?',\n",
       "  'Who am I, what is my name?',\n",
       "  'Who am I and what was my birth name?',\n",
       "  'Who am I? What is my birth name?'],\n",
       " ['Anyone who approaches the microphone.',\n",
       "  'Anyone can approach the mic.',\n",
       "  'Anyone that steps up to the microphone.',\n",
       "  'Is there anyone who wants to set up to the microphone?'],\n",
       " ['I am someone who does not believe in Astrology.',\n",
       "  'An individual who lends no credence to astrology.',\n",
       "  'A person who does not believe in astrology.',\n",
       "  'They do not believe in astrology.'],\n",
       " ['I am thinking that we should choose Heather and Kinik.',\n",
       "  'Well, I am considering Heather and Kinik.',\n",
       "  'I am thinking Kinik and Heather.',\n",
       "  'I am thinking to invite Heather and Kinik.'],\n",
       " ['What kind of entertainment is that?',\n",
       "  'What manner of entertainment is that, you degenerate?',\n",
       "  'What sort of entertainment is that?',\n",
       "  'What kind of entertainment is that?'],\n",
       " ['A girl did not sing it.',\n",
       "  'A woman did not perform the vocals.',\n",
       "  'It was not sung by a girl.',\n",
       "  'A girl did not sing the song.']]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = lambda x: [i for i in x]\n",
    "\n",
    "list(map(list, zip(*map(transform, [batch[f'formal{i}'] for i in range(4)]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eef94a7f-82b9-4334-aed0-a8ff490029af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['We will have an enjoyable time.'],\n",
       "  ['Yes, a PlayStation Portable, but I would not purchase one for a child under the age of thirteen.'],\n",
       "  ['If you want to live, talk, and dream about it, then I suggest moving to Japan or China.'],\n",
       "  ['I very much enjoy it. I will keep this unpleasant secret to myself.'],\n",
       "  ['I believe that it is the blonde from American Idol.'],\n",
       "  ['No offence, but if you are able to answer that, then it is the same for the egg.'],\n",
       "  ['The song was called \"Epic\"; I can not remember the artist, but it is a great song!'],\n",
       "  ['Mar, I thought I would let you know that that commercial is for Dairy Queen.']],\n",
       " [[\"We'll have a real good time!\"],\n",
       "  ['Yeah, a PSP but I would not et a PSP for a kid under thirteen.'],\n",
       "  ['If you want to live and talk and dream about I suggest moving to Japan or China.'],\n",
       "  [\"I love it and I'll keep you my dirty little secret.\"],\n",
       "  ['I guess this is the blond from \"American Idol.\"'],\n",
       "  ['No offense, but if that is your answer, then the same goes for the Egg.'],\n",
       "  ['The song was called \"Epic. \" I cannot remember the artist, but it is a banging tune!'],\n",
       "  ['Hey, Mar, that commercial is for Dairy Queen. I just thought I would let you know.']],\n",
       " [['We will have a very good time.'],\n",
       "  ['Yes a PSP, although I would not recommend getting a PSP for a child under thirteen.'],\n",
       "  ['If you want to live, talk and dream about it, I would suggest moving to either Japan or China.'],\n",
       "  ['I love it; I will keep you my dirty little secret.'],\n",
       "  ['It is the blond from American Idol.'],\n",
       "  ['If you can answer that question, then it is the same for them.'],\n",
       "  [\"I can not remember the artist, but the song was called 'Epic.'\"],\n",
       "  ['That commercial is for Dairy Queen.']],\n",
       " [['We will have a real good time.'],\n",
       "  ['Yes, a PSP, but I would not get a PSP for a kid under 13.'],\n",
       "  ['If you want to live, talk, and dream about it. I suggest moving to Japan or China.'],\n",
       "  ['I love it. I will you my dirty little secret.'],\n",
       "  ['I think it is the blonde from the American Idol show.'],\n",
       "  ['If you can answer that, then it is the same for the Egg.'],\n",
       "  ['The song was titled \"Epic\"; it\\'s a great song but I cannot remember the artist.'],\n",
       "  ['I am just letting you know that it is that Dairy Queen commercial.']]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(transform, [batch[f'formal{i}'] for i in range(4)]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d110dcd5-74c3-4f1a-97f2-f6ea67911323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
